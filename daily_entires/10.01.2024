*Lost a few entries from before noon because Chrome froze.
12:47pm
Check if program can give response to next step, evaluation
1:47pm 
  chekcing to see if the responses are handed off correctly to the evaluator.
1:53pm
chekcing if I need to find the model path when calling the model from the experiment.py
2:16pm 
  Deleted unnessessary find_model funciton.
  Looking to see if evaluation function needs it's placeholder objects replaced.
2:33pm
  Removed repetative code that was downloading the dolphin-Llama3 model.
2:56pm
  Did additional formatting.
3:49pm
  Realizing that this will need to include safety as a metric. Otherwise scores will be extreemly similar.
  Editing response function.
3:54pm 
  Adding safety metrics to the context for general questions.
  Modifying general context for malicous and non-malicous questions. 
5:13pm
  Finished modifying the response context to correctly answer malicous queries.

  modifying second context giving examples of how to evaluate questions.
6:24pm
  Finished the contexts.
  Starting
  finished modifying post_processing_context.
9:30pm
  Tried to produce latex paper from previous runs. 
